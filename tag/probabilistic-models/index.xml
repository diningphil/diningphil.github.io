<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Probabilistic Models | Federico Errica</title>
    <link>https://diningphil.github.io/tag/probabilistic-models/</link>
      <atom:link href="https://diningphil.github.io/tag/probabilistic-models/index.xml" rel="self" type="application/rss+xml" />
    <description>Probabilistic Models</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 15 Jan 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://diningphil.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Probabilistic Models</title>
      <link>https://diningphil.github.io/tag/probabilistic-models/</link>
    </image>
    
    <item>
      <title>Paper accepted at ICLR 2024!!</title>
      <link>https://diningphil.github.io/post/24_iclr/</link>
      <pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/24_iclr/</guid>
      <description>&lt;p&gt;Graph-Induced Sum-Product Networks have been (finally!) accepted at ICLR 2024! Blog post coming in the following months&amp;hellip; stay tuned! Special thanks to Mathias Niepert for his relentless support =).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tractable Probabilistic Graph Representation Learning with Graph-Induced Sum-Product Networks</title>
      <link>https://diningphil.github.io/publication/2024_iclr/</link>
      <pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2024_iclr/</guid>
      <description>&lt;p&gt;We propose a probabilistic model that bridges graph machine learning and sum-product networks to tractably answer probabilistic queries. Our Graph-induced Sum-Product Network can solve unsupervised and supervised graph tasks and it is especially effective in modeling the missing data distribution as well as exploiting unlabeled data in a scarce supervision scenario.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at ICML 2022!!</title>
      <link>https://diningphil.github.io/post/22_icgmm/</link>
      <pubDate>Sun, 15 May 2022 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/22_icgmm/</guid>
      <description>&lt;p&gt;After a year of hard work, rejections, good feedback, paper rewriting, and additional experiments, our Infinite Contextual Graph Markov Model has been accepted at ICML 2022!&lt;/p&gt;
&lt;p&gt;iCGMM combines graph learning and Bayesian nonparametric to build a deep model that can decide the complexity of each of its layers and automatize the choice of its hyper-parameters during training.&lt;/p&gt;
&lt;p&gt;Needless to say, this work wouldn&amp;rsquo;t have been possible without the incredible expertise of Daniele Castellana about BNP methods and the supervision of Davide Bacciu and Alessio Micheli. Kudos to this incredible team!&lt;/p&gt;
&lt;p&gt;If you don&amp;rsquo;t want to wait for the proceedings, please consider taking a look at Section 4.3 of my PhD thesis (link at the top of the homepage).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at ICML 2021!!</title>
      <link>https://diningphil.github.io/post/21_icml/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/21_icml/</guid>
      <description>&lt;p&gt;Wonderful news! Our paper &amp;ldquo;Graph Mixture Density Networks&amp;rdquo; has been accepted at ICML 2021! Shout out to my supervisors &lt;a href=&#34;http://pages.di.unipi.it/micheli/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Alessio Micheli&lt;/a&gt; and &lt;a href=&#34;http://pages.di.unipi.it/bacciu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Davide Bacciu&lt;/a&gt; that made this possible. We study the problem of learning multi-modal output distributions conditioned on arbitrary input graphs. With GMDN, we can predict if there&amp;rsquo;s more than one likely outcome associated with an input graph: this is especially useful, for example, when predicting the final outcome of a pandemic when the social network is known. We will release the camera ready very soon!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2 Papers accepted at IJCNN 2021!</title>
      <link>https://diningphil.github.io/post/21_ijcnn/</link>
      <pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/21_ijcnn/</guid>
      <description>&lt;p&gt;Two papers accepted at IJCNN 2021! The first, &amp;ldquo;Modeling Edge Features with Deep Graph Bayesian Networks&amp;rdquo;, extends the Contextual Graph Markov Model to the processing of arbitrary edge features! The second, &amp;ldquo;Concept Matching for Low-resource Classification&amp;rdquo;, presents a new way to train prototypes of important words to perform classification when supervised data is limited. You can find the papers on my publication list! Congrats to all my co-authors!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
