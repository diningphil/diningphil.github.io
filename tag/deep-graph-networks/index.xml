<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Graph Networks | Federico Errica</title>
    <link>https://diningphil.github.io/tag/deep-graph-networks/</link>
      <atom:link href="https://diningphil.github.io/tag/deep-graph-networks/index.xml" rel="self" type="application/rss+xml" />
    <description>Deep Graph Networks</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://diningphil.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Deep Graph Networks</title>
      <link>https://diningphil.github.io/tag/deep-graph-networks/</link>
    </image>
    
    <item>
      <title>Paper accepted at NeurIPS 2024!!</title>
      <link>https://diningphil.github.io/post/24_neurips/</link>
      <pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/24_neurips/</guid>
      <description>&lt;p&gt;Did you know that you can build expressive and efficient equivariant message passing for molecular systems using Cartesian rather than Spherical tensors (e.g., MACE)? If not, it&amp;rsquo;s time to have a look at our NeurIPS 24 paper led by Viktor!! Huge congrats to him and excellent team effort!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at ICLR 2024!!</title>
      <link>https://diningphil.github.io/post/24_iclr/</link>
      <pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/24_iclr/</guid>
      <description>&lt;p&gt;Graph-Induced Sum-Product Networks have been (finally!) accepted at ICLR 2024! Blog post coming in the following months&amp;hellip; stay tuned! Special thanks to Mathias Niepert for his relentless support =).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tractable Probabilistic Graph Representation Learning with Graph-Induced Sum-Product Networks</title>
      <link>https://diningphil.github.io/publication/2024_iclr/</link>
      <pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2024_iclr/</guid>
      <description>&lt;p&gt;We propose a probabilistic model that bridges graph machine learning and sum-product networks to tractably answer probabilistic queries. Our Graph-induced Sum-Product Network can solve unsupervised and supervised graph tasks and it is especially effective in modeling the missing data distribution as well as exploiting unlabeled data in a scarce supervision scenario.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PyDGN accepted at JOSS!</title>
      <link>https://diningphil.github.io/post/23_joss/</link>
      <pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/23_joss/</guid>
      <description>&lt;p&gt;PyDGN just got accepted in Journal of Open Source Software =)&lt;/p&gt;
&lt;p&gt;I have to say, compared to other prestigious journals, I got much more constructive feedback and the review process was faster and transparent. Thank you to the editor and the reviewers!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at NeurIPS 2023!!</title>
      <link>https://diningphil.github.io/post/23_neurips/</link>
      <pubDate>Sun, 24 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/23_neurips/</guid>
      <description>&lt;p&gt;I am really excited: my very first single-author paper has been accepted at NeurIPS 2023! I still can&amp;rsquo;t believe that I managed to pull this off, especially after submitting it for the first time =) give it a few weeks for the papers to be released on OpenReview!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at ICML 2022!!</title>
      <link>https://diningphil.github.io/post/22_icgmm/</link>
      <pubDate>Sun, 15 May 2022 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/22_icgmm/</guid>
      <description>&lt;p&gt;After a year of hard work, rejections, good feedback, paper rewriting, and additional experiments, our Infinite Contextual Graph Markov Model has been accepted at ICML 2022!&lt;/p&gt;
&lt;p&gt;iCGMM combines graph learning and Bayesian nonparametric to build a deep model that can decide the complexity of each of its layers and automatize the choice of its hyper-parameters during training.&lt;/p&gt;
&lt;p&gt;Needless to say, this work wouldn&amp;rsquo;t have been possible without the incredible expertise of Daniele Castellana about BNP methods and the supervision of Davide Bacciu and Alessio Micheli. Kudos to this incredible team!&lt;/p&gt;
&lt;p&gt;If you don&amp;rsquo;t want to wait for the proceedings, please consider taking a look at Section 4.3 of my PhD thesis (link at the top of the homepage).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PyDGN 1.0.0</title>
      <link>https://diningphil.github.io/post/22_pydgn-1.0.0/</link>
      <pubDate>Wed, 02 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/22_pydgn-1.0.0/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/diningphil/PyDGN&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyDGN&lt;/a&gt; 1.0.0 is out! We have added a documentation, refactored the code, implemented a bunch of user-friendly features and provided clean, well commented configuration files!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PyDGN v0.5.0 is out!</title>
      <link>https://diningphil.github.io/post/21_pydgn050/</link>
      <pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/21_pydgn050/</guid>
      <description>&lt;p&gt;We officially released the 0.5.0 version of our &lt;a href=&#34;https://github.com/diningphil/PyDGN&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyDGN&lt;/a&gt; library! We have added a bunch of useful features, refactored the code, and fixed some bugs! Special thanks to &lt;a href=&#34;http://pages.di.unipi.it/numeroso/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Danilo Numeroso&lt;/a&gt; who implemented a very useful and flexible random search technique!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at ICML 2021!!</title>
      <link>https://diningphil.github.io/post/21_icml/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/21_icml/</guid>
      <description>&lt;p&gt;Wonderful news! Our paper &amp;ldquo;Graph Mixture Density Networks&amp;rdquo; has been accepted at ICML 2021! Shout out to my supervisors &lt;a href=&#34;http://pages.di.unipi.it/micheli/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Alessio Micheli&lt;/a&gt; and &lt;a href=&#34;http://pages.di.unipi.it/bacciu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Davide Bacciu&lt;/a&gt; that made this possible. We study the problem of learning multi-modal output distributions conditioned on arbitrary input graphs. With GMDN, we can predict if there&amp;rsquo;s more than one likely outcome associated with an input graph: this is especially useful, for example, when predicting the final outcome of a pandemic when the social network is known. We will release the camera ready very soon!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2 Papers accepted at IJCNN 2021!</title>
      <link>https://diningphil.github.io/post/21_ijcnn/</link>
      <pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/21_ijcnn/</guid>
      <description>&lt;p&gt;Two papers accepted at IJCNN 2021! The first, &amp;ldquo;Modeling Edge Features with Deep Graph Bayesian Networks&amp;rdquo;, extends the Contextual Graph Markov Model to the processing of arbitrary edge features! The second, &amp;ldquo;Concept Matching for Low-resource Classification&amp;rdquo;, presents a new way to train prototypes of important words to perform classification when supervised data is limited. You can find the papers on my publication list! Congrats to all my co-authors!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at WWW 2021 Workshop!</title>
      <link>https://diningphil.github.io/post/21_workshopwww/</link>
      <pubDate>Wed, 17 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/21_workshopwww/</guid>
      <description>&lt;p&gt;Together with &lt;a href=&#34;http://pages.di.unipi.it/carta/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Antonio Carta&lt;/a&gt;, &lt;a href=&#34;https://andreacossu.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Andrea Cossu&lt;/a&gt;, and &lt;a href=&#34;http://pages.di.unipi.it/bacciu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Davide Bacciu&lt;/a&gt;, our paper &amp;ldquo;Catastrophic Forgetting in Deep Graph Networks: an Introductory Benchmark for Graph Classification&amp;rdquo; has been accepted for publication at the &lt;a href=&#34;https://graph-learning-benchmarks.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WWW&#39;21 Workshop on Graph Learning Benchmarks&lt;/a&gt;. We study whether known continual learning techniques have an impact when applied to graphs, but we also observe that structure-preserving regularization may help. Also, a structure-agnostic baseline shows strong performances in this scenario &lt;a href=&#34;https://iclr.cc/virtual_2020/poster_HygDF6NFPB.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(again)&lt;/a&gt;, indicating that there is much to be done at the intersection of the Continual Learning and Graph Representation Learning fields!
EDIT: it has also been selected as one of the two orals of the workshop! Great news :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at Frontiers Molecular Biosciences!</title>
      <link>https://diningphil.github.io/post/21_pisatrento/</link>
      <pubDate>Tue, 09 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/21_pisatrento/</guid>
      <description>&lt;p&gt;Our paper &lt;a href=&#34;https://www.frontiersin.org/articles/10.3389/fmolb.2021.637396/abstract&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;A deep graph network-enhanced sampling approach to efficiently explore the space of reduced representations of proteins&amp;rdquo;&lt;/a&gt; has been accepted for publication in Frontiers Molecular Biosciences. Together with the &lt;a href=&#34;https://twitter.com/r_potestio?lang=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Potestio Lab&lt;/a&gt;, we trained a deep graph networks to approximate a complex measure of information retention in proteins after a coarse-graining process is applied. PDF available soon!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PyDGN v0.4.0 is out!</title>
      <link>https://diningphil.github.io/post/20_pydgn040/</link>
      <pubDate>Sun, 13 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/20_pydgn040/</guid>
      <description>&lt;p&gt;We officially released the 0.4.0 version of our PyDGN library! In the past few months the library has become more mature, and I summarized its main features in this short 

&lt;a href=&#34;https://diningphil.github.io/media/PyDGNv0_4_0-intro-slides.pdf&#34; target=&#34;_blank&#34;&gt;presentation&lt;/a&gt;
. Version 0.4.0 features the addition of the Ray library to handle multiprocessing as well as distributed computing! To make an example, you can run parallel experiments on your local laptop, on different GPUs at the same time or even on a cluster of machines! Special thanks to &lt;a href=&#34;http://pages.di.unipi.it/carta/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Antonio Carta&lt;/a&gt; who made a wonderful porting of Ray into PyDGN! Now…back to research! :)&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
