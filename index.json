[{"authors":null,"categories":null,"content":"Federico Errica is a PhD candidate in Computer Science at the University of Pisa, supervised by Alessio Micheli and Davide Bacciu. His research interests include deep probabilistic models for graphs, neural networks and hybrid architectures. He is part of the Computational Intelligence and Machine Learning Group and of the Pervasive AI Lab\n  Download my CV.\n","date":1644624000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1644624000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Federico Errica is a PhD candidate in Computer Science at the University of Pisa, supervised by Alessio Micheli and Davide Bacciu. His research interests include deep probabilistic models for graphs, neural networks and hybrid architectures.","tags":null,"title":"Federico Errica","type":"authors"},{"authors":["Federico Errica"],"categories":[],"content":"Working on Graph ML? Please consider submitting to our LOD2022 special session \u0026ldquo;Recent Advances in Deep Learning for Graphs\u0026rdquo; üéâ With a dream team of co-organizers, including the pioneers of DGNs A. Micheli and F. Scarselli! Looking forward to physically ü§ù you in the beautiful Certosa di Pontignano, Italy!\n","date":1644624000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644624000,"objectID":"4210942ce589da8679bf018a9259ddf2","permalink":"https://diningphil.github.io/post/22_lod2022/","publishdate":"2022-02-12T00:00:00Z","relpermalink":"/post/22_lod2022/","section":"post","summary":"Working on Graph ML? Please consider submitting to our LOD2022 special session \u0026ldquo;Recent Advances in Deep Learning for Graphs\u0026rdquo; üéâ With a dream team of co-organizers, including the pioneers of DGNs A.","tags":["special-session"],"title":"Special Session on DL4G at LOD2022","type":"post"},{"authors":["Federico Errica"],"categories":[],"content":"While I prepare my Ph.D. thesis' defense, I have just started working for NEC Laboratories Europe as a Research Scientist! The people and the environment are truly stimulating, stay tuned for more updates on deep learning for graphs =).\n","date":1642032000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642032000,"objectID":"173007e09dcbbadba4a18cc6e1d5cfd7","permalink":"https://diningphil.github.io/post/22_nec/","publishdate":"2022-01-13T00:00:00Z","relpermalink":"/post/22_nec/","section":"post","summary":"While I prepare my Ph.D. thesis' defense, I have just started working for NEC Laboratories Europe as a Research Scientist! The people and the environment are truly stimulating, stay tuned for more updates on deep learning for graphs =).","tags":["job"],"title":"Started a new job","type":"post"},{"authors":["Luca Oneto","Nicolo Navarin","Battista Biggio","Federico Errica","Alessio Micheli","Franco Scarselli","Monica Bianchini","Alessandro Sperduti"],"categories":null,"content":"","date":1631318400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631318400,"objectID":"a40331dbddf324bbf764bbcc726f8f1b","permalink":"https://diningphil.github.io/publication/2021_esann_b/","publishdate":"2021-09-11T00:00:00Z","relpermalink":"/publication/2021_esann_b/","section":"publication","summary":"","tags":[],"title":"Complex Data: Learning Trustworthily, Automatically, and with Guarantees","type":"publication"},{"authors":["Federico Errica","Giacomo Iadarola","Fabio Martinelli","Francesco Mercaldo","Alessio Micheli"],"categories":null,"content":"","date":1631318400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631318400,"objectID":"be1fd2de3f2ed589c2d4db66afdeb49a","permalink":"https://diningphil.github.io/publication/2021_esann/","publishdate":"2021-09-11T00:00:00Z","relpermalink":"/publication/2021_esann/","section":"publication","summary":"","tags":[],"title":"Robust Malware Classification via Deep Graph Networks on Call Graph Topologies","type":"publication"},{"authors":["Federico Errica"],"categories":[],"content":"We officially released the 0.5.0 version of our PyDGN library! We have added a bunch of useful features, refactored the code, and fixed some bugs! Special thanks to Danilo Numeroso who implemented a very useful and flexible random search technique!\n","date":1628812800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628812800,"objectID":"45b911e9da2263f1f61e3763847b78ac","permalink":"https://diningphil.github.io/post/21_pydgn050/","publishdate":"2021-08-13T00:00:00Z","relpermalink":"/post/21_pydgn050/","section":"post","summary":"PyDGN v0.5.0 is out","tags":["software"],"title":"PyDGN v0.5.0 is out!","type":"post"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways: - **Create** slides using Wowchemy's [*Slides*](https://wowchemy.com/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://wowchemy.com/docs/writing-markdown-latex/). Further event details, including [page elements](https://wowchemy.com/docs/writing-markdown-latex/) such as image galleries, can be added to the body of this page. -- ","date":1626872400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626872400,"objectID":"6128da41f56555a02252cad8e8733a96","permalink":"https://diningphil.github.io/talk/nec-labs-europe/","publishdate":"2021-07-21T00:00:00Z","relpermalink":"/talk/nec-labs-europe/","section":"event","summary":"I talked about my PhD research","tags":[],"title":"NEC Labs Europe","type":"event"},{"authors":["Federico Errica"],"categories":[],"content":"Wonderful news! Our paper \u0026ldquo;Graph Mixture Density Networks\u0026rdquo; has been accepted at ICML 2021! Shout out to my supervisors Alessio Micheli and Davide Bacciu that made this possible. We study the problem of learning multi-modal output distributions conditioned on arbitrary input graphs. With GMDN, we can predict if there\u0026rsquo;s more than one likely outcome associated with an input graph: this is especially useful, for example, when predicting the final outcome of a pandemic when the social network is known. We will release the camera ready very soon!\n","date":1620518400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620518400,"objectID":"d33a92f32a285e1aa2644c3b831ce78f","permalink":"https://diningphil.github.io/post/21_icml/","publishdate":"2021-05-09T00:00:00Z","relpermalink":"/post/21_icml/","section":"post","summary":"Deep Bayesian Graph Networks \u0026 Hybrid Methods","tags":[],"title":"GMDN got accepted at ICML'21!","type":"post"},{"authors":["Federico Errica","Davide Bacciu","Alessio Micheli"],"categories":null,"content":"Combining Deep Graph Networks with Mixture Density Networks to model multimodal output distributions conditioned on arbitrary input graphs.\n","date":1620518400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620518400,"objectID":"6fe4058c19abc3d2e5e08f61f4c7c00c","permalink":"https://diningphil.github.io/publication/2021_icml/","publishdate":"2021-05-09T00:00:00Z","relpermalink":"/publication/2021_icml/","section":"publication","summary":"Combining Deep Graph Networks with Mixture Density Networks to model multimodal output distributions conditioned on arbitrary input graphs.","tags":[],"title":"Graph Mixture Density Networks","type":"publication"},{"authors":["Federico Errica"],"categories":[],"content":"Two papers accepted at IJCNN 2021! The first, \u0026ldquo;Modeling Edge Features with Deep Graph Bayesian Networks\u0026rdquo;, extends the Contextual Graph Markov Model to the processing of arbitrary edge features! The second, \u0026ldquo;Concept Matching for Low-resource Classification\u0026rdquo;, presents a new way to train prototypes of important words to perform classification when supervised data is limited. You can find the papers on my publication list! Congrats to all my co-authors!\n","date":1618272000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618272000,"objectID":"7649e64d75ffb4c38cbcaf69556b03f8","permalink":"https://diningphil.github.io/post/21_ijcnn/","publishdate":"2021-04-13T00:00:00Z","relpermalink":"/post/21_ijcnn/","section":"post","summary":"Deep Bayesian Graph Networks \u0026 Low-resource Classification","tags":["paper","conference"],"title":"2 Papers at IJCNN'21","type":"post"},{"authors":["Federico Errica","Fabrizio Silvestri","Bora Edizel","Ludovic Denoyer","Fabio Petroni","Vassilis Plachouras","Sebastian Riedel"],"categories":null,"content":"","date":1618272000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618272000,"objectID":"438ab5df44132dabf42eb40c0c7f428c","permalink":"https://diningphil.github.io/publication/2021_ijcnn_parcus/","publishdate":"2021-04-13T00:00:00Z","relpermalink":"/publication/2021_ijcnn_parcus/","section":"publication","summary":"","tags":[],"title":"Concept Matching for Low-Resource Classification","type":"publication"},{"authors":["Daniele Atzeni","Davide Bacciu","Federico Errica","Alessio Micheli"],"categories":null,"content":"","date":1618272000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618272000,"objectID":"e4b7f7da4a592869d612ff945af02e8d","permalink":"https://diningphil.github.io/publication/2021_ijcnn_ecgmm/","publishdate":"2021-04-13T00:00:00Z","relpermalink":"/publication/2021_ijcnn_ecgmm/","section":"publication","summary":"","tags":[],"title":"Modeling Edge Features with Deep Bayesian Graph Networks","type":"publication"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways: - **Create** slides using Wowchemy's [*Slides*](https://wowchemy.com/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://wowchemy.com/docs/writing-markdown-latex/). Further event details, including [page elements](https://wowchemy.com/docs/writing-markdown-latex/) such as image galleries, can be added to the body of this page. -- ","date":1617973200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617973200,"objectID":"ae0b3e02c93fc8a67c0da32244586b0b","permalink":"https://diningphil.github.io/talk/continual-ai/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/continual-ai/","section":"event","summary":"I talked about our latest work on catastrophic forgetting for DGNs.","tags":[],"title":"Continual AI","type":"event"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways: - **Create** slides using Wowchemy's [*Slides*](https://wowchemy.com/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://wowchemy.com/docs/writing-markdown-latex/). Further event details, including [page elements](https://wowchemy.com/docs/writing-markdown-latex/) such as image galleries, can be added to the body of this page. -- ","date":1617714000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617714000,"objectID":"ee8d9c7288d8db890c30859eca8469f1","permalink":"https://diningphil.github.io/talk/ibm-research-zurich/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/ibm-research-zurich/","section":"event","summary":"I talked about our latest research on deep learning for graphs.","tags":[],"title":"IBM Research Zurich","type":"event"},{"authors":["Federico Errica"],"categories":[],"content":"Together with Antonio Carta, Andrea Cossu, and Davide Bacciu, our paper \u0026ldquo;Catastrophic Forgetting in Deep Graph Networks: an Introductory Benchmark for Graph Classification\u0026rdquo; has been accepted for publication at the WWW'21 Workshop on Graph Learning Benchmarks. We study whether known continual learning techniques have an impact when applied to graphs, but we also observe that structure-preserving regularization may help. Also, a structure-agnostic baseline shows strong performances in this scenario (again), indicating that there is much to be done at the intersection of the Continual Learning and Graph Representation Learning fields! EDIT: it has also been selected as one of the two orals of the workshop! Great news :)\n","date":1615939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615939200,"objectID":"7bb0fa8fcaeb33c70b3dbe1b3e5b51a5","permalink":"https://diningphil.github.io/post/21_workshopwww/","publishdate":"2021-03-17T00:00:00Z","relpermalink":"/post/21_workshopwww/","section":"post","summary":"Continual Learning for Graphs","tags":["paper","workshop"],"title":"Paper at WWW'21 Workshop","type":"post"},{"authors":["Federico Errica"],"categories":[],"content":"Our paper \u0026ldquo;A deep graph network-enhanced sampling approach to efficiently explore the space of reduced representations of proteins\u0026rdquo; has been accepted for publication in Frontiers Molecular Biosciences. Together with the Potestio Lab, we trained a deep graph networks to approximate a complex measure of information retention in proteins after a coarse-graining process is applied. PDF available soon!\n","date":1615248000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615248000,"objectID":"00ba5af8be314ded5351482155a7a7cb","permalink":"https://diningphil.github.io/post/21_pisatrento/","publishdate":"2021-03-09T00:00:00Z","relpermalink":"/post/21_pisatrento/","section":"post","summary":"Approximating information loss on chemical molecules","tags":["paper","journal"],"title":"Paper in Frontiers Molecular Biosciences","type":"post"},{"authors":["Federico Errica","Marco Giulini","Davide Bacciu","Roberto Menichetti","Alessio Micheli","Raffaello Potestio"],"categories":null,"content":"Learning complex measure of information loss in reduce representations of proteins via deep graph networks.\n","date":1613520000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613520000,"objectID":"6f2c104bcaf4d62cf19306d64cac1678","permalink":"https://diningphil.github.io/publication/2021_frontiers/","publishdate":"2021-02-17T00:00:00Z","relpermalink":"/publication/2021_frontiers/","section":"publication","summary":"Learning complex measure of information loss in reduce representations of proteins via deep graph networks.","tags":[],"title":"A deep graph network-enhanced sampling approach to efficiently explore the space of reduced representations of proteins","type":"publication"},{"authors":["Antonio Carta","Andrea Cossu","Federico Errica","Davide Bacciu"],"categories":null,"content":"An empirical work at the intersection of Continual Learning and Graph Representation Learning. Selected as one of the two oral presentations.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"ebfe60b539137cb5cdb9b4e4ebd8cfca","permalink":"https://diningphil.github.io/publication/2021_grl_www/","publishdate":"2021-03-16T00:00:00Z","relpermalink":"/publication/2021_grl_www/","section":"publication","summary":"An empirical work at the intersection of Continual Learning and Graph Representation Learning. Selected as one of the two oral presentations.","tags":[],"title":"Catastrophic Forgetting in Deep Graph Networks: an Introductory Benchmark for Graph Classification","type":"publication"},{"authors":["Federico Errica","Davide Bacciu","Alessio Micheli"],"categories":null,"content":"","date":1601510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601510400,"objectID":"03a96dadb856fdc2ba4f1f0dd086ecb4","permalink":"https://diningphil.github.io/publication/2020_esann/","publishdate":"2020-10-01T00:00:00Z","relpermalink":"/publication/2020_esann/","section":"publication","summary":"","tags":[],"title":"Theoretically Expressive and Edge-aware Graph Learning","type":"publication"},{"authors":["Federico Errica"],"categories":[],"content":"We officially released the 0.4.0 version of our PyDGN library! In the past few months the library has become more mature, and I summarized its main features in this short presentation. Version 0.4.0 features the addition of the Ray library to handle multiprocessing as well as distributed computing! To make an example, you can run parallel experiments on your local laptop, on different GPUs at the same time or even on a cluster of machines! Special thanks to Antonio Carta who made a wonderful porting of Ray into PyDGN! Now‚Ä¶back to research! :)\n","date":1599955200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599955200,"objectID":"1ce86ba3c8280cd93b4173865dd56cc9","permalink":"https://diningphil.github.io/post/20_pydgn040/","publishdate":"2020-09-13T00:00:00Z","relpermalink":"/post/20_pydgn040/","section":"post","summary":"PyDGN v0.4.0 is out","tags":["software"],"title":"PyDGN v0.4.0 is out!","type":"post"},{"authors":["Federico Errica","Marco Giulini","Davide Bacciu","Roberto Menichetti","Alessio Micheli","Raffaello Potestio"],"categories":null,"content":"","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596240000,"objectID":"b28647958c8944d33f5faa04a9879811","permalink":"https://diningphil.github.io/publication/2020_pisa_trento/","publishdate":"2020-08-01T00:00:00Z","relpermalink":"/publication/2020_pisa_trento/","section":"publication","summary":"","tags":[],"title":"Accelerating the identification of informative reduced representations of proteins with deep learning for graphs","type":"publication"},{"authors":["Davide Bacciu","Federico Errica","Alessio Micheli"],"categories":null,"content":"Further studies on the Contextual Graph Markov Model.\n","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"7f4a3f3327d344a3d960aa21118d4173","permalink":"https://diningphil.github.io/publication/2020_jmlr/","publishdate":"2020-07-01T00:00:00Z","relpermalink":"/publication/2020_jmlr/","section":"publication","summary":"Further studies on the Contextual Graph Markov Model.","tags":[],"title":"Probabilistic Learning on Graphs via Contextual Architectures","type":"publication"},{"authors":["Davide Bacciu","Federico Errica","Marco Podda","Alessio Micheli"],"categories":null,"content":"A top-down approach to the field of machine learning for graphs.\n","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590969600,"objectID":"c51f82fb41d714de3ac48600fc9e0931","permalink":"https://diningphil.github.io/publication/2020_neunet/","publishdate":"2020-06-01T00:00:00Z","relpermalink":"/publication/2020_neunet/","section":"publication","summary":"A top-down approach to the field of machine learning for graphs.","tags":[],"title":"A Gentle Introduction to Deep Learning for Graphs","type":"publication"},{"authors":["Federico Errica","Marco Podda","Davide Bacciu","Alessio Micheli"],"categories":null,"content":"A fair and robust evaluation of Deep Graph Networks for graph classification tasks.\n","date":1587340800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587340800,"objectID":"b2947a7ddc7c05e60afd4f41f674fc7a","permalink":"https://diningphil.github.io/publication/2020_iclr/","publishdate":"2020-04-20T00:00:00Z","relpermalink":"/publication/2020_iclr/","section":"publication","summary":"A fair and robust evaluation of Deep Graph Networks for graph classification tasks.","tags":[],"title":"A Fair Comparison of Graph Neural Networks for Graph Classification","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  **Two**  Three   A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://diningphil.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"One of the most popular articles of the last years in the Machine Learning community is the Auto-Encoding Variational Bayes, which also includes the so-called reparametrization trick. Intrigued by what was sketched in the article, I decided to work out the details of this reparametrization, covering 2 of the 3 cases described (but I guess the third one can be derived from the first 2). I want to share my calculations with you. I have learned (and reviewed) a lot in the process, which was not directly related to the equations themselves. Sharing is the only way to make real progress as a community. Have a look Here, and please contact me in case the steps are not correct or contain imprecise notation.\nUpdate, 2018-12-10: I have added the solution of the integrals of Appendix B. This was really useful to get familiar with the gaussian integral and Fubini\u0026rsquo;s theorem.\nSpecial thanks to Iacopo Ripoli for his decisive and helpful insights!\n","date":1543968000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543968000,"objectID":"dbd93246fc1eb8e3330bf716b46269c4","permalink":"https://diningphil.github.io/project/reparamtrick/","publishdate":"2018-12-05T00:00:00Z","relpermalink":"/project/reparamtrick/","section":"project","summary":"One of the most popular articles of the last years in the Machine Learning community is the Auto-Encoding Variational Bayes, which also includes the so-called reparametrization trick. Intrigued by what was sketched in the article, I decided to work out the details of this reparametrization, covering 2 of the 3 cases described (but I guess the third one can be derived from the first 2).","tags":["Variational Auto-Encoders"],"title":"Notes on the Reparametrization Trick","type":"project"},{"authors":null,"categories":null,"content":"Recently I was looking at Stochastic Neigbhor Embedding (SNE) and its t-distributed version (t-SNE), but I could not find the exact steps to derive the gradient of the loss function (there are small errors in the t-SNE article and no info in the SNE one), so I decided to carry on the derivation and share it. I hope this can be of any help to those who are studying the same topic. Here you find the pdf: please let me know if you spot an error! (Picture taken from t-SNE paper)\n","date":1543363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543363200,"objectID":"9766a6c3ce0353c95f6543376e1db216","permalink":"https://diningphil.github.io/project/tsnederivation/","publishdate":"2018-11-28T00:00:00Z","relpermalink":"/project/tsnederivation/","section":"project","summary":"Recently I was looking at Stochastic Neigbhor Embedding (SNE) and its t-distributed version (t-SNE), but I could not find the exact steps to derive the gradient of the loss function (there are small errors in the t-SNE article and no info in the SNE one), so I decided to carry on the derivation and share it.","tags":["Dimensionality Reduction"],"title":"Derivations of SNE and t-SNE","type":"project"},{"authors":["Davide Bacciu","Federico Errica","Alessio Micheli"],"categories":null,"content":"A deep, probabilistic, and scalable machine learning model for graphs. Work done as part of my master thesis.\n","date":1530403200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530403200,"objectID":"7deb69ff69cdf1373be7914e8f7e79f7","permalink":"https://diningphil.github.io/publication/2018_icml/","publishdate":"2018-07-01T00:00:00Z","relpermalink":"/publication/2018_icml/","section":"publication","summary":"A deep, probabilistic, and scalable machine learning model for graphs. Work done as part of my master thesis.","tags":[],"title":"Contextual Graph Markov Model: a Deep and Generative Approach to Graph Processing","type":"publication"},{"authors":null,"categories":null,"content":"Wiki Description This is a Python library to easily experiment with Deep Graph Networks (DGNs). It provides automatic management of data splitting, loading and the most common experimental settings. It also handles both model selection and risk assessment procedures, by trying many different configurations in parallel (CPU). This repository is built upon the Pytorch Geometric Library, which provides support for data management.\nIf you happen to use or modify this code, please remember to cite our tutorial paper:\nBacciu Davide, Errica Federico, Micheli Alessio, Podda Marco: A Gentle Introduction to Deep Learning for Graphs, Neural Networks, 2020. DOI: 10.1016/j.neunet.2020.06.006.\nIf you are interested in a rigorous evaluation of Deep Graph Networks, check this out:\nErrica Federico, Podda Marco, Bacciu Davide, Micheli Alessio: A Fair Comparison of Graph Neural Networks for Graph Classification. Proceedings of the 8th International Conference on Learning Representations (ICLR 2020). Code\nNew features\n Support to multiprocessing in GPU is now provided via Ray (see v0.4.0)!  Installation: (We assume git and Miniconda/Anaconda are installed)\nFirst, make sure gcc 5.2.0 is installed: conda install -c anaconda libgcc=5.2.0. Then, echo $LD_LIBRARY_PATH should always contain :/home/[your user name]/miniconda3/lib. Then run from your terminal the following command:\nsource install.sh [\u0026lt;your_cuda_version\u0026gt;]  Where \u0026lt;your_cuda_version\u0026gt; is an optional argument that can be either cpu, cu92, cu101, cu102 or cu110 for Pytorch 1.7.0. If you do not provide a cuda version, the script will default to cpu. The script will create a virtual environment named pydgn, with all the required packages needed to run our code. Important: do NOT run this command using bash instead of source!\nRemember that PyTorch MacOS Binaries dont support CUDA, install from source if CUDA is needed\nUsage: Preprocess your dataset (see also Wiki) python build_dataset.py --config-file [your data config file]  Launch an experiment in debug mode (see also Wiki) python launch_experiment.py --config-file [your exp. config file] --splits-folder [the splits MAIN folder] --data-splits [the splits file] --data-root [root folder of your data] --dataset-name [name of the dataset] --dataset-class [class that handles the dataset] --max-cpus [max cpu parallelism] --max-gpus [max gpu parallelism] --gpus-per-task [how many gpus to allocate for each job] --final-training-runs [how many final runs when evaluating on test. Results are averaged] --result-folder [folder where to store results]  To debug your code it is useful to add --debug to the command above. Notice, however, that the CLI will not work as expected here, as code will be executed sequentially. After debugging, if you need sequential execution, you can use --max-cpus 1 --max-gpus 1 --gpus-per-task [0/1] without the --debug option.\nCredits: This is a joint project with Marco Podda (Github/Homepage), whom I thank for his relentless dedication.\nMany thanks to Antonio Carta (Github/Homepage) for incorporating the Ray library (see v0.4.0) into PyDGN! This will be of tremendous help.\nContributing This research software is provided as-is. We are working on this library in our spare time.\nIf you find a bug, please open an issue to report it, and we will do our best to solve it. For generic/technical questions, please email us rather than opening an issue.\nLicense: PyDGN is GPL 3.0 licensed, as written in the LICENSE file.\nTroubleshooting If you get errors like /lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found:\n make sure gcc 5.2.0 is installed: conda install -c anaconda libgcc=5.2.0 echo $LD_LIBRARY_PATH should contain :/home/[your user name]/[your anaconda or miniconda folder name]/lib after checking the above points, you can reinstall everything with pip using the --no-cache-dir option  ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"133d8a37732ba0d7563b6186b28948ec","permalink":"https://diningphil.github.io/project/pydgn/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/pydgn/","section":"project","summary":"A Python library to easily experiment with Deep Graph Networks.","tags":["Deep Learning","Graphs"],"title":"PyDGN","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://diningphil.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]