<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Federico Errica</title>
    <link>https://diningphil.github.io/</link>
      <atom:link href="https://diningphil.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Federico Errica</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://diningphil.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Federico Errica</title>
      <link>https://diningphil.github.io/</link>
    </image>
    
    <item>
      <title>History repeats itself: A Baseline for Temporal Knowledge Graph Forecasting</title>
      <link>https://diningphil.github.io/publication/2024_ijcai/</link>
      <pubDate>Wed, 24 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2024_ijcai/</guid>
      <description>&lt;p&gt;We propose a temporal knowledge graph baseline based on the simple principle of recurrency. Surprisingly, a simple approach like this beats state of the art methods based on representation learning on 3 out of 5 commonly used datasets!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at IJCAI 2024!!</title>
      <link>https://diningphil.github.io/post/24_ijcai/</link>
      <pubDate>Wed, 24 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/24_ijcai/</guid>
      <description>&lt;p&gt;Did you know a simple recurrency baseline is enough to beat complex state of the
art methods for temporal knowledge graph forecasting? Check our upcoming IJCAI paper! Shout out to Julia&amp;rsquo;s hard work!!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>University of Stuttgart</title>
      <link>https://diningphil.github.io/talk/university-of-stuttgart/</link>
      <pubDate>Sun, 07 Apr 2024 13:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/talk/university-of-stuttgart/</guid>
      <description>&lt;!-- 

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Slides can be added in a few ways:

- **Create** slides using Wowchemy&#39;s [*Slides*](https://wowchemy.com/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file
- **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file
- **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://wowchemy.com/docs/writing-markdown-latex/).

Further event details, including [page elements](https://wowchemy.com/docs/writing-markdown-latex/) such as image galleries, can be added to the body of this page. --&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at ICLR 2024!!</title>
      <link>https://diningphil.github.io/post/24_iclr/</link>
      <pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/24_iclr/</guid>
      <description>&lt;p&gt;Graph-Induced Sum-Product Networks have been (finally!) accepted at ICLR 2024! Blog post coming in the following months&amp;hellip; stay tuned! Special thanks to Mathias Niepert for his relentless support =).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tractable Probabilistic Graph Representation Learning with Graph-Induced Sum-Product Networks</title>
      <link>https://diningphil.github.io/publication/2024_iclr/</link>
      <pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2024_iclr/</guid>
      <description>&lt;p&gt;We propose a probabilistic model that bridges graph machine learning and sum-product networks to tractably answer probabilistic queries. Our Graph-induced Sum-Product Network can solve unsupervised and supervised graph tasks and it is especially effective in modeling the missing data distribution as well as exploiting unlabeled data in a scarce supervision scenario.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On Class Distributions Induced by Nearest Neighbor Graphs for Node Classification of Tabular Data</title>
      <link>https://diningphil.github.io/publication/2023_neurips/</link>
      <pubDate>Sat, 16 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2023_neurips/</guid>
      <description>&lt;p&gt;In this paper I try to address the following question: &amp;ldquo;Is it really worth to build a k-Nearest Neighbor graph from tabular data and then apply deep graph nets on top of it to classify each sample in the table?&amp;rdquo; This is something people tend to do, and I have always been skeptical about it. Now we have a very good indication, which I also tried to justify theoretically, that a k-NN graph is not the best structure to use if we want to gain some real advantages (under some mild conditions). I also argue that new methods of building synthetic graphs are necessary if we want to exploit some &amp;ldquo;latent&amp;rdquo; structure between the samples of a dataset.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at JCP!!</title>
      <link>https://diningphil.github.io/post/23_jcp/</link>
      <pubDate>Mon, 27 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/23_jcp/</guid>
      <description>&lt;p&gt;Our work on learning to accelerate Hamiltonian Monte Carlo simulations has been accepted at the Journal of Chemical Physics! Shout out to my colleagues Henrik and Francesco for the hard work =)&lt;/p&gt;
&lt;p&gt;Stay tuned for more work on machine learning for the computational sciences =).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Self-Tuning Hamiltonian Monte Carlo for Accelerated Sampling</title>
      <link>https://diningphil.github.io/publication/2023_jcp/</link>
      <pubDate>Mon, 27 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2023_jcp/</guid>
      <description>&lt;p&gt;In this paper we accelerate HMC simulations by learning atom-dependent timesteps and the number of molecular dynamics steps! With an appropriate choice of the loss, we can significantly speed up simulations and reduce autocorrelation times by 25% on alanine dipeptide.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hidden Markov Models for Temporal Graph Representation Learning</title>
      <link>https://diningphil.github.io/publication/2023_esann/</link>
      <pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2023_esann/</guid>
      <description>&lt;p&gt;We extend HMMs to graphs!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PyDGN accepted at JOSS!</title>
      <link>https://diningphil.github.io/post/23_joss/</link>
      <pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/23_joss/</guid>
      <description>&lt;p&gt;PyDGN just got accepted in Journal of Open Source Software =)&lt;/p&gt;
&lt;p&gt;I have to say, compared to other prestigious journals, I got much more constructive feedback and the review process was faster and transparent. Thank you to the editor and the reviewers!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PyDGN: a Python Library for Flexible and Reproducible Research on Deep Learning for Graphs</title>
      <link>https://diningphil.github.io/publication/2023_joss/</link>
      <pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2023_joss/</guid>
      <description>&lt;p&gt;This is a Python library to easily experiment with Deep Graph Networks (DGNs). It provides automatic management of data splitting, loading and common experimental settings. It also handles both model selection and risk assessment procedures, by trying many different configurations in parallel (CPU or GPU).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at NeurIPS 2023!!</title>
      <link>https://diningphil.github.io/post/23_neurips/</link>
      <pubDate>Sun, 24 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/23_neurips/</guid>
      <description>&lt;p&gt;I am really excited: my very first single-author paper has been accepted at NeurIPS 2023! I still can&amp;rsquo;t believe that I managed to pull this off, especially after submitting it for the first time =) give it a few weeks for the papers to be released on OpenReview!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Investigating the Interplay between Features and Structures in Graph Learning</title>
      <link>https://diningphil.github.io/publication/2023_ecml/</link>
      <pubDate>Fri, 08 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2023_ecml/</guid>
      <description>&lt;p&gt;We investigate the quality of quantitative measures that assess the utility of a graph structure for node classification tasks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PhD Course on Probabilistic Reasoning in ML</title>
      <link>https://diningphil.github.io/talk/phd-course-on-probabilistic-reasoning-in-ml/</link>
      <pubDate>Thu, 23 Feb 2023 13:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/talk/phd-course-on-probabilistic-reasoning-in-ml/</guid>
      <description>&lt;!-- 

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Slides can be added in a few ways:

- **Create** slides using Wowchemy&#39;s [*Slides*](https://wowchemy.com/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file
- **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file
- **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://wowchemy.com/docs/writing-markdown-latex/).

Further event details, including [page elements](https://wowchemy.com/docs/writing-markdown-latex/) such as image galleries, can be added to the body of this page. --&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at ICML 2022!!</title>
      <link>https://diningphil.github.io/post/22_icgmm/</link>
      <pubDate>Sun, 15 May 2022 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/22_icgmm/</guid>
      <description>&lt;p&gt;After a year of hard work, rejections, good feedback, paper rewriting, and additional experiments, our Infinite Contextual Graph Markov Model has been accepted at ICML 2022!&lt;/p&gt;
&lt;p&gt;iCGMM combines graph learning and Bayesian nonparametric to build a deep model that can decide the complexity of each of its layers and automatize the choice of its hyper-parameters during training.&lt;/p&gt;
&lt;p&gt;Needless to say, this work wouldn&amp;rsquo;t have been possible without the incredible expertise of Daniele Castellana about BNP methods and the supervision of Davide Bacciu and Alessio Micheli. Kudos to this incredible team!&lt;/p&gt;
&lt;p&gt;If you don&amp;rsquo;t want to wait for the proceedings, please consider taking a look at Section 4.3 of my PhD thesis (link at the top of the homepage).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Infinite Contextual Graph Markov Model</title>
      <link>https://diningphil.github.io/publication/2022_icml/</link>
      <pubDate>Sun, 15 May 2022 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2022_icml/</guid>
      <description>&lt;p&gt;Combining Deep Graph Networks with Bayesian nonparametric techniques to unsupervised learning of node/graph representations while automatizing the choice of the hyper-parameters during training.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Towards Learning Trustworthily, Automatically, and with Guarantees on Graphs: an Overview</title>
      <link>https://diningphil.github.io/publication/2022_neurocomputing/</link>
      <pubDate>Fri, 15 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2022_neurocomputing/</guid>
      <description>&lt;p&gt;An overview of the current works focused towards learning trustworthily, automatically, and with guarantees on graphs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PyDGN 1.0.0</title>
      <link>https://diningphil.github.io/post/22_pydgn-1.0.0/</link>
      <pubDate>Wed, 02 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/22_pydgn-1.0.0/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/diningphil/PyDGN&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyDGN&lt;/a&gt; 1.0.0 is out! We have added a documentation, refactored the code, implemented a bunch of user-friendly features and provided clean, well commented configuration files!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Catastrophic Forgetting in Deep Graph Networks: A Graph Classification Benchmark</title>
      <link>https://diningphil.github.io/publication/2022_frontiers/</link>
      <pubDate>Wed, 02 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2022_frontiers/</guid>
      <description>&lt;p&gt;We study the phenomenon of catastrophic forgetting in the graph representation learning scenario.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Started a new job</title>
      <link>https://diningphil.github.io/post/22_nec/</link>
      <pubDate>Thu, 13 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/22_nec/</guid>
      <description>&lt;p&gt;While I prepare my Ph.D. thesis&amp;rsquo; defense, I have just started working for &lt;a href=&#34;https://www.neclab.eu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NEC Laboratories Europe&lt;/a&gt; as a Research Scientist! The people and the environment are truly stimulating, stay tuned for more updates on deep learning for graphs =).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Robust Malware Classification via Deep Graph Networks on Call Graph Topologies</title>
      <link>https://diningphil.github.io/publication/2021_esann/</link>
      <pubDate>Sat, 11 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2021_esann/</guid>
      <description></description>
    </item>
    
    <item>
      <title>PyDGN v0.5.0 is out!</title>
      <link>https://diningphil.github.io/post/21_pydgn050/</link>
      <pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/21_pydgn050/</guid>
      <description>&lt;p&gt;We officially released the 0.5.0 version of our &lt;a href=&#34;https://github.com/diningphil/PyDGN&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyDGN&lt;/a&gt; library! We have added a bunch of useful features, refactored the code, and fixed some bugs! Special thanks to &lt;a href=&#34;http://pages.di.unipi.it/numeroso/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Danilo Numeroso&lt;/a&gt; who implemented a very useful and flexible random search technique!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NEC Labs Europe</title>
      <link>https://diningphil.github.io/talk/nec-labs-europe/</link>
      <pubDate>Wed, 21 Jul 2021 13:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/talk/nec-labs-europe/</guid>
      <description>&lt;!-- 

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Slides can be added in a few ways:

- **Create** slides using Wowchemy&#39;s [*Slides*](https://wowchemy.com/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file
- **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file
- **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://wowchemy.com/docs/writing-markdown-latex/).

Further event details, including [page elements](https://wowchemy.com/docs/writing-markdown-latex/) such as image galleries, can be added to the body of this page. --&gt;
</description>
    </item>
    
    <item>
      <title>Graph Mixture Density Networks</title>
      <link>https://diningphil.github.io/publication/2021_icml/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2021_icml/</guid>
      <description>&lt;p&gt;Combining Deep Graph Networks with Mixture Density Networks to model multimodal output distributions conditioned on arbitrary input graphs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at ICML 2021!!</title>
      <link>https://diningphil.github.io/post/21_icml/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/21_icml/</guid>
      <description>&lt;p&gt;Wonderful news! Our paper &amp;ldquo;Graph Mixture Density Networks&amp;rdquo; has been accepted at ICML 2021! Shout out to my supervisors &lt;a href=&#34;http://pages.di.unipi.it/micheli/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Alessio Micheli&lt;/a&gt; and &lt;a href=&#34;http://pages.di.unipi.it/bacciu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Davide Bacciu&lt;/a&gt; that made this possible. We study the problem of learning multi-modal output distributions conditioned on arbitrary input graphs. With GMDN, we can predict if there&amp;rsquo;s more than one likely outcome associated with an input graph: this is especially useful, for example, when predicting the final outcome of a pandemic when the social network is known. We will release the camera ready very soon!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2 Papers accepted at IJCNN 2021!</title>
      <link>https://diningphil.github.io/post/21_ijcnn/</link>
      <pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/21_ijcnn/</guid>
      <description>&lt;p&gt;Two papers accepted at IJCNN 2021! The first, &amp;ldquo;Modeling Edge Features with Deep Graph Bayesian Networks&amp;rdquo;, extends the Contextual Graph Markov Model to the processing of arbitrary edge features! The second, &amp;ldquo;Concept Matching for Low-resource Classification&amp;rdquo;, presents a new way to train prototypes of important words to perform classification when supervised data is limited. You can find the papers on my publication list! Congrats to all my co-authors!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Concept Matching for Low-Resource Classification</title>
      <link>https://diningphil.github.io/publication/2021_ijcnn_parcus/</link>
      <pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2021_ijcnn_parcus/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Modeling Edge Features with Deep Bayesian Graph Networks</title>
      <link>https://diningphil.github.io/publication/2021_ijcnn_ecgmm/</link>
      <pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2021_ijcnn_ecgmm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Continual AI</title>
      <link>https://diningphil.github.io/talk/continual-ai/</link>
      <pubDate>Fri, 09 Apr 2021 13:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/talk/continual-ai/</guid>
      <description>&lt;!-- 

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Slides can be added in a few ways:

- **Create** slides using Wowchemy&#39;s [*Slides*](https://wowchemy.com/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file
- **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file
- **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://wowchemy.com/docs/writing-markdown-latex/).

Further event details, including [page elements](https://wowchemy.com/docs/writing-markdown-latex/) such as image galleries, can be added to the body of this page. --&gt;
</description>
    </item>
    
    <item>
      <title>IBM Research Zurich</title>
      <link>https://diningphil.github.io/talk/ibm-research-zurich/</link>
      <pubDate>Tue, 06 Apr 2021 13:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/talk/ibm-research-zurich/</guid>
      <description>&lt;!-- 

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Slides can be added in a few ways:

- **Create** slides using Wowchemy&#39;s [*Slides*](https://wowchemy.com/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file
- **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file
- **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://wowchemy.com/docs/writing-markdown-latex/).

Further event details, including [page elements](https://wowchemy.com/docs/writing-markdown-latex/) such as image galleries, can be added to the body of this page. --&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at WWW 2021 Workshop!</title>
      <link>https://diningphil.github.io/post/21_workshopwww/</link>
      <pubDate>Wed, 17 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/21_workshopwww/</guid>
      <description>&lt;p&gt;Together with &lt;a href=&#34;http://pages.di.unipi.it/carta/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Antonio Carta&lt;/a&gt;, &lt;a href=&#34;https://andreacossu.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Andrea Cossu&lt;/a&gt;, and &lt;a href=&#34;http://pages.di.unipi.it/bacciu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Davide Bacciu&lt;/a&gt;, our paper &amp;ldquo;Catastrophic Forgetting in Deep Graph Networks: an Introductory Benchmark for Graph Classification&amp;rdquo; has been accepted for publication at the &lt;a href=&#34;https://graph-learning-benchmarks.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WWW&#39;21 Workshop on Graph Learning Benchmarks&lt;/a&gt;. We study whether known continual learning techniques have an impact when applied to graphs, but we also observe that structure-preserving regularization may help. Also, a structure-agnostic baseline shows strong performances in this scenario &lt;a href=&#34;https://iclr.cc/virtual_2020/poster_HygDF6NFPB.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(again)&lt;/a&gt;, indicating that there is much to be done at the intersection of the Continual Learning and Graph Representation Learning fields!
EDIT: it has also been selected as one of the two orals of the workshop! Great news :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at Frontiers Molecular Biosciences!</title>
      <link>https://diningphil.github.io/post/21_pisatrento/</link>
      <pubDate>Tue, 09 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/21_pisatrento/</guid>
      <description>&lt;p&gt;Our paper &lt;a href=&#34;https://www.frontiersin.org/articles/10.3389/fmolb.2021.637396/abstract&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;A deep graph network-enhanced sampling approach to efficiently explore the space of reduced representations of proteins&amp;rdquo;&lt;/a&gt; has been accepted for publication in Frontiers Molecular Biosciences. Together with the &lt;a href=&#34;https://twitter.com/r_potestio?lang=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Potestio Lab&lt;/a&gt;, we trained a deep graph networks to approximate a complex measure of information retention in proteins after a coarse-graining process is applied. PDF available soon!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A deep graph network-enhanced sampling approach to efficiently explore the space of reduced representations of proteins</title>
      <link>https://diningphil.github.io/publication/2021_frontiers/</link>
      <pubDate>Wed, 17 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2021_frontiers/</guid>
      <description>&lt;p&gt;Learning complex measure of information loss in reduce representations of proteins via deep graph networks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Catastrophic Forgetting in Deep Graph Networks: an Introductory Benchmark for Graph Classification</title>
      <link>https://diningphil.github.io/publication/2021_grl_www/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2021_grl_www/</guid>
      <description>&lt;p&gt;An empirical work at the intersection of Continual Learning and Graph Representation Learning. &lt;strong&gt;Selected as one of the two oral presentations&lt;/strong&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Theoretically Expressive and Edge-aware Graph Learning</title>
      <link>https://diningphil.github.io/publication/2020_esann/</link>
      <pubDate>Thu, 01 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2020_esann/</guid>
      <description></description>
    </item>
    
    <item>
      <title>PyDGN v0.4.0 is out!</title>
      <link>https://diningphil.github.io/post/20_pydgn040/</link>
      <pubDate>Sun, 13 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/20_pydgn040/</guid>
      <description>&lt;p&gt;We officially released the 0.4.0 version of our PyDGN library! In the past few months the library has become more mature, and I summarized its main features in this short 

&lt;a href=&#34;https://diningphil.github.io/media/PyDGNv0_4_0-intro-slides.pdf&#34; target=&#34;_blank&#34;&gt;presentation&lt;/a&gt;
. Version 0.4.0 features the addition of the Ray library to handle multiprocessing as well as distributed computing! To make an example, you can run parallel experiments on your local laptop, on different GPUs at the same time or even on a cluster of machines! Special thanks to &lt;a href=&#34;http://pages.di.unipi.it/carta/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Antonio Carta&lt;/a&gt; who made a wonderful porting of Ray into PyDGN! Now…back to research! :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Accelerating the identification of informative reduced representations of proteins with deep learning for graphs</title>
      <link>https://diningphil.github.io/publication/2020_pisa_trento/</link>
      <pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2020_pisa_trento/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Probabilistic Learning on Graphs via Contextual Architectures</title>
      <link>https://diningphil.github.io/publication/2020_jmlr/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2020_jmlr/</guid>
      <description>&lt;p&gt;Further studies on the Contextual Graph Markov Model.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Gentle Introduction to Deep Learning for Graphs</title>
      <link>https://diningphil.github.io/publication/2020_neunet/</link>
      <pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2020_neunet/</guid>
      <description>&lt;p&gt;A top-down approach to the field of machine learning for graphs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Fair Comparison of Graph Neural Networks for Graph Classification</title>
      <link>https://diningphil.github.io/publication/2020_iclr/</link>
      <pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2020_iclr/</guid>
      <description>&lt;p&gt;A fair and robust evaluation of Deep Graph Networks for graph classification tasks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://diningphil.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-hugo-blox-builder&#34;&gt;Create slides in Markdown with Hugo Blox Builder&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://hugoblox.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo Blox Builder&lt;/a&gt; | &lt;a href=&#34;https://docs.hugoblox.com/content/slides/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://revealjs.com/pdf-export/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Eating...&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} One {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} **Two** {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} Three {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
  One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  &lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  Three
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Only the speaker can read these notes
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Press &lt;span class=&#34;sb&#34;&gt;`S`&lt;/span&gt; key to view
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {{% /speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/media/boards.jpg&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;#0000FF&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;my-style&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-css&#34; data-lang=&#34;css&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h3&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;navy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://discord.gg/z8wNYzb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.hugoblox.com/content/slides/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Notes on the Reparametrization Trick</title>
      <link>https://diningphil.github.io/project/reparamtrick/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/project/reparamtrick/</guid>
      <description>&lt;p&gt;One of the most popular articles of the last years in the Machine Learning community is the &lt;a href=&#34;https://arxiv.org/pdf/1312.6114.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Auto-Encoding Variational Bayes&lt;/a&gt;, which also includes the so-called reparametrization trick. Intrigued by what was sketched in the article, I decided to work out the details of this reparametrization, covering 2 of the 3 cases described (but I guess the third one can be derived from the first 2). I want to share my calculations with you. I have learned (and reviewed) a lot in the process, which was not directly related to the equations themselves. Sharing is the only way to make real progress as a community. Have a look 

&lt;a href=&#34;https://diningphil.github.io/uploads/reparamtrick_notes.pdf&#34; target=&#34;_blank&#34;&gt;Here&lt;/a&gt;
, and please contact me in case the steps are not correct or contain imprecise notation.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update, 2018-12-10&lt;/em&gt;: I have added the solution of the integrals of Appendix B. This was really useful to get familiar with the gaussian integral and Fubini&amp;rsquo;s theorem.&lt;/p&gt;
&lt;p&gt;Special thanks to Iacopo Ripoli for his decisive and helpful insights!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Derivations of SNE and t-SNE</title>
      <link>https://diningphil.github.io/project/tsnederivation/</link>
      <pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/project/tsnederivation/</guid>
      <description>&lt;p&gt;Recently I was looking at Stochastic Neighbor Embedding &lt;a href=&#34;https://papers.nips.cc/paper/2276-stochastic-neighbor-embedding.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(SNE)&lt;/a&gt; and its t-distributed version &lt;a href=&#34;http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(t-SNE)&lt;/a&gt;, but I could not find the exact steps to derive the gradient of the loss function (there are small errors in the t-SNE article and no info in the SNE one), so I decided to carry on the derivation and share it. I hope this can be of any help to those who are studying the same topic. 

&lt;a href=&#34;https://diningphil.github.io/uploads/sne_tsne.pdf&#34; target=&#34;_blank&#34;&gt;Here&lt;/a&gt;
 you find the pdf: please let me know if you spot an error! (Picture taken from t-SNE paper)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Contextual Graph Markov Model: a Deep and Generative Approach to Graph Processing</title>
      <link>https://diningphil.github.io/publication/2018_icml/</link>
      <pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2018_icml/</guid>
      <description>&lt;p&gt;A deep, probabilistic, and scalable machine learning model for graphs. Work done as part of my master thesis.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at npj Computational Materials!!</title>
      <link>https://diningphil.github.io/post/24_npj/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/24_npj/</guid>
      <description>&lt;p&gt;Our work on uncertainty-biased molecular dynamics for machine-learning interatomic potentials has been accepted at the npj Computational Materials! Great team achievement led by Viktor!!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Uncertainty-biased molecular dynamics for learning uniformly accurate interatomic potentials</title>
      <link>https://diningphil.github.io/publication/2024_npj/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2024_npj/</guid>
      <description>&lt;p&gt;In this paper we combine uncertainty-biased molecular dynamics with active learning to show how we can learn machine learning interatomic potential (MLIP) models that are more robust to predictions on extrapolative regions.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
