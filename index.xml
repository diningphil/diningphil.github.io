<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Federico Errica</title>
    <link>https://diningphil.github.io/</link>
      <atom:link href="https://diningphil.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Federico Errica</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 08 Sep 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://diningphil.github.io/media/icon_hu811ba3e0cc5bb0ab65be55bc8716bf2a_48188_512x512_fill_lanczos_center_3.png</url>
      <title>Federico Errica</title>
      <link>https://diningphil.github.io/</link>
    </image>
    
    <item>
      <title>Investigating the Interplay between Features and Structures in Graph Learning</title>
      <link>https://diningphil.github.io/publication/2023_ecml/</link>
      <pubDate>Fri, 08 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2023_ecml/</guid>
      <description>&lt;p&gt;We investigate the quality of quantitative measures that assess the utility of a graph structure for node classification tasks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tractable Probabilistic Graph Representation Learning with Graph-Induced Sum-Product Networks</title>
      <link>https://diningphil.github.io/publication/2023_gspn/</link>
      <pubDate>Fri, 08 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2023_gspn/</guid>
      <description>&lt;p&gt;We propose a probabilistic model that bridges graph machine learning and sum-product networks to
tractably answer probabilistic queries. Our Graph-induced Sum-Product Network can solve unsupervised and supervised graph tasks and it is especially effective in modeling the missing data distribution as well as exploiting unlabeled data in a scarce supervision scenario.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper accepted at ICML 2022</title>
      <link>https://diningphil.github.io/post/22_icgmm/</link>
      <pubDate>Sun, 15 May 2022 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/22_icgmm/</guid>
      <description>&lt;p&gt;After a year of hard work, rejections, good feedback, paper rewriting, and additional experiments, our Infinite Contextual Graph Markov Model has been accepted at ICML 2022!&lt;/p&gt;
&lt;p&gt;iCGMM combines graph learning and Bayesian nonparametric to build a deep model that can decide the complexity of each of its layers and automatize the choice of its hyper-parameters during training.&lt;/p&gt;
&lt;p&gt;Needless to say, this work wouldn&amp;rsquo;t have been possible without the incredible expertise of Daniele Castellana about BNP methods and the supervision of Davide Bacciu and Alessio Micheli. Kudos to this incredible team!&lt;/p&gt;
&lt;p&gt;If you don&amp;rsquo;t want to wait for the proceedings, please consider taking a look at Section 4.3 of my PhD thesis (link at the top of the homepage).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Infinite Contextual Graph Markov Model</title>
      <link>https://diningphil.github.io/publication/2022_icml/</link>
      <pubDate>Sun, 15 May 2022 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2022_icml/</guid>
      <description>&lt;p&gt;Combining Deep Graph Networks with Bayesian nonparametric techniques to unsupervised learning of node/graph representations while automatizing the choice of the hyper-parameters during training.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Towards Learning Trustworthily, Automatically, and with Guarantees on Graphs: an Overview</title>
      <link>https://diningphil.github.io/publication/2022_neurocomputing/</link>
      <pubDate>Fri, 15 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2022_neurocomputing/</guid>
      <description>&lt;p&gt;An overview of the current works focused towards learning trustworthily, automatically, and with guarantees on graphs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PyDGN 1.0.0</title>
      <link>https://diningphil.github.io/post/22_pydgn-1.0.0/</link>
      <pubDate>Wed, 02 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/22_pydgn-1.0.0/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/diningphil/PyDGN&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyDGN&lt;/a&gt; 1.0.0 is out! We have added a documentation, refactored the code, implemented a bunch of user-friendly features and provided clean, well commented configuration files!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Catastrophic Forgetting in Deep Graph Networks: A Graph Classification Benchmark</title>
      <link>https://diningphil.github.io/publication/2022_frontiers/</link>
      <pubDate>Wed, 02 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2022_frontiers/</guid>
      <description>&lt;p&gt;We study the phenomenon of catastrophic forgetting in the graph representation learning scenario.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Started a new job</title>
      <link>https://diningphil.github.io/post/22_nec/</link>
      <pubDate>Thu, 13 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/22_nec/</guid>
      <description>&lt;p&gt;While I prepare my Ph.D. thesis&amp;rsquo; defense, I have just started working for &lt;a href=&#34;https://www.neclab.eu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NEC Laboratories Europe&lt;/a&gt; as a Research Scientist! The people and the environment are truly stimulating, stay tuned for more updates on deep learning for graphs =).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Robust Malware Classification via Deep Graph Networks on Call Graph Topologies</title>
      <link>https://diningphil.github.io/publication/2021_esann/</link>
      <pubDate>Sat, 11 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2021_esann/</guid>
      <description></description>
    </item>
    
    <item>
      <title>PyDGN v0.5.0 is out!</title>
      <link>https://diningphil.github.io/post/21_pydgn050/</link>
      <pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/21_pydgn050/</guid>
      <description>&lt;p&gt;We officially released the 0.5.0 version of our &lt;a href=&#34;https://github.com/diningphil/PyDGN&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyDGN&lt;/a&gt; library! We have added a bunch of useful features, refactored the code, and fixed some bugs! Special thanks to &lt;a href=&#34;http://pages.di.unipi.it/numeroso/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Danilo Numeroso&lt;/a&gt; who implemented a very useful and flexible random search technique!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NEC Labs Europe</title>
      <link>https://diningphil.github.io/talk/nec-labs-europe/</link>
      <pubDate>Wed, 21 Jul 2021 13:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/talk/nec-labs-europe/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Slides can be added in a few ways:

- **Create** slides using Wowchemy&#39;s [*Slides*](https://wowchemy.com/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file
- **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file
- **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://wowchemy.com/docs/writing-markdown-latex/).

Further event details, including [page elements](https://wowchemy.com/docs/writing-markdown-latex/) such as image galleries, can be added to the body of this page. --&gt;
</description>
    </item>
    
    <item>
      <title>GMDN got accepted at ICML&#39;21!</title>
      <link>https://diningphil.github.io/post/21_icml/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/21_icml/</guid>
      <description>&lt;p&gt;Wonderful news! Our paper &amp;ldquo;Graph Mixture Density Networks&amp;rdquo; has been accepted at ICML 2021! Shout out to my supervisors &lt;a href=&#34;http://pages.di.unipi.it/micheli/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Alessio Micheli&lt;/a&gt; and &lt;a href=&#34;http://pages.di.unipi.it/bacciu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Davide Bacciu&lt;/a&gt; that made this possible. We study the problem of learning multi-modal output distributions conditioned on arbitrary input graphs. With GMDN, we can predict if there&amp;rsquo;s more than one likely outcome associated with an input graph: this is especially useful, for example, when predicting the final outcome of a pandemic when the social network is known. We will release the camera ready very soon!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Graph Mixture Density Networks</title>
      <link>https://diningphil.github.io/publication/2021_icml/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2021_icml/</guid>
      <description>&lt;p&gt;Combining Deep Graph Networks with Mixture Density Networks to model multimodal output distributions conditioned on arbitrary input graphs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2 Papers at IJCNN&#39;21</title>
      <link>https://diningphil.github.io/post/21_ijcnn/</link>
      <pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/21_ijcnn/</guid>
      <description>&lt;p&gt;Two papers accepted at IJCNN 2021! The first, &amp;ldquo;Modeling Edge Features with Deep Graph Bayesian Networks&amp;rdquo;, extends the Contextual Graph Markov Model to the processing of arbitrary edge features! The second, &amp;ldquo;Concept Matching for Low-resource Classification&amp;rdquo;, presents a new way to train prototypes of important words to perform classification when supervised data is limited. You can find the papers on my publication list! Congrats to all my co-authors!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Concept Matching for Low-Resource Classification</title>
      <link>https://diningphil.github.io/publication/2021_ijcnn_parcus/</link>
      <pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2021_ijcnn_parcus/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Modeling Edge Features with Deep Bayesian Graph Networks</title>
      <link>https://diningphil.github.io/publication/2021_ijcnn_ecgmm/</link>
      <pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2021_ijcnn_ecgmm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Continual AI</title>
      <link>https://diningphil.github.io/talk/continual-ai/</link>
      <pubDate>Fri, 09 Apr 2021 13:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/talk/continual-ai/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Slides can be added in a few ways:

- **Create** slides using Wowchemy&#39;s [*Slides*](https://wowchemy.com/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file
- **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file
- **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://wowchemy.com/docs/writing-markdown-latex/).

Further event details, including [page elements](https://wowchemy.com/docs/writing-markdown-latex/) such as image galleries, can be added to the body of this page. --&gt;
</description>
    </item>
    
    <item>
      <title>IBM Research Zurich</title>
      <link>https://diningphil.github.io/talk/ibm-research-zurich/</link>
      <pubDate>Tue, 06 Apr 2021 13:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/talk/ibm-research-zurich/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Slides can be added in a few ways:

- **Create** slides using Wowchemy&#39;s [*Slides*](https://wowchemy.com/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file
- **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file
- **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://wowchemy.com/docs/writing-markdown-latex/).

Further event details, including [page elements](https://wowchemy.com/docs/writing-markdown-latex/) such as image galleries, can be added to the body of this page. --&gt;
</description>
    </item>
    
    <item>
      <title>Paper at WWW&#39;21 Workshop</title>
      <link>https://diningphil.github.io/post/21_workshopwww/</link>
      <pubDate>Wed, 17 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/21_workshopwww/</guid>
      <description>&lt;p&gt;Together with &lt;a href=&#34;http://pages.di.unipi.it/carta/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Antonio Carta&lt;/a&gt;, &lt;a href=&#34;https://andreacossu.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Andrea Cossu&lt;/a&gt;, and &lt;a href=&#34;http://pages.di.unipi.it/bacciu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Davide Bacciu&lt;/a&gt;, our paper &amp;ldquo;Catastrophic Forgetting in Deep Graph Networks: an Introductory Benchmark for Graph Classification&amp;rdquo; has been accepted for publication at the &lt;a href=&#34;https://graph-learning-benchmarks.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WWW&#39;21 Workshop on Graph Learning Benchmarks&lt;/a&gt;. We study whether known continual learning techniques have an impact when applied to graphs, but we also observe that structure-preserving regularization may help. Also, a structure-agnostic baseline shows strong performances in this scenario &lt;a href=&#34;https://iclr.cc/virtual_2020/poster_HygDF6NFPB.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(again)&lt;/a&gt;, indicating that there is much to be done at the intersection of the Continual Learning and Graph Representation Learning fields!
EDIT: it has also been selected as one of the two orals of the workshop! Great news :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper in Frontiers Molecular Biosciences</title>
      <link>https://diningphil.github.io/post/21_pisatrento/</link>
      <pubDate>Tue, 09 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/21_pisatrento/</guid>
      <description>&lt;p&gt;Our paper &lt;a href=&#34;https://www.frontiersin.org/articles/10.3389/fmolb.2021.637396/abstract&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;A deep graph network-enhanced sampling approach to efficiently explore the space of reduced representations of proteins&amp;rdquo;&lt;/a&gt; has been accepted for publication in Frontiers Molecular Biosciences. Together with the &lt;a href=&#34;https://twitter.com/r_potestio?lang=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Potestio Lab&lt;/a&gt;, we trained a deep graph networks to approximate a complex measure of information retention in proteins after a coarse-graining process is applied. PDF available soon!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A deep graph network-enhanced sampling approach to efficiently explore the space of reduced representations of proteins</title>
      <link>https://diningphil.github.io/publication/2021_frontiers/</link>
      <pubDate>Wed, 17 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2021_frontiers/</guid>
      <description>&lt;p&gt;Learning complex measure of information loss in reduce representations of proteins via deep graph networks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Catastrophic Forgetting in Deep Graph Networks: an Introductory Benchmark for Graph Classification</title>
      <link>https://diningphil.github.io/publication/2021_grl_www/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2021_grl_www/</guid>
      <description>&lt;p&gt;An empirical work at the intersection of Continual Learning and Graph Representation Learning. &lt;strong&gt;Selected as one of the two oral presentations&lt;/strong&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Theoretically Expressive and Edge-aware Graph Learning</title>
      <link>https://diningphil.github.io/publication/2020_esann/</link>
      <pubDate>Thu, 01 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2020_esann/</guid>
      <description></description>
    </item>
    
    <item>
      <title>PyDGN v0.4.0 is out!</title>
      <link>https://diningphil.github.io/post/20_pydgn040/</link>
      <pubDate>Sun, 13 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/post/20_pydgn040/</guid>
      <description>&lt;p&gt;We officially released the 0.4.0 version of our PyDGN library! In the past few months the library has become more mature, and I summarized its main features in this short &lt;a href=&#34;https://diningphil.github.io/media/PyDGNv0_4_0-intro-slides.pdf&#34; target=&#34;_blank&#34;&gt;presentation&lt;/a&gt;. Version 0.4.0 features the addition of the Ray library to handle multiprocessing as well as distributed computing! To make an example, you can run parallel experiments on your local laptop, on different GPUs at the same time or even on a cluster of machines! Special thanks to &lt;a href=&#34;http://pages.di.unipi.it/carta/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Antonio Carta&lt;/a&gt; who made a wonderful porting of Ray into PyDGN! Nowâ€¦back to research! :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Accelerating the identification of informative reduced representations of proteins with deep learning for graphs</title>
      <link>https://diningphil.github.io/publication/2020_pisa_trento/</link>
      <pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2020_pisa_trento/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Probabilistic Learning on Graphs via Contextual Architectures</title>
      <link>https://diningphil.github.io/publication/2020_jmlr/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2020_jmlr/</guid>
      <description>&lt;p&gt;Further studies on the Contextual Graph Markov Model.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Gentle Introduction to Deep Learning for Graphs</title>
      <link>https://diningphil.github.io/publication/2020_neunet/</link>
      <pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2020_neunet/</guid>
      <description>&lt;p&gt;A top-down approach to the field of machine learning for graphs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Fair Comparison of Graph Neural Networks for Graph Classification</title>
      <link>https://diningphil.github.io/publication/2020_iclr/</link>
      <pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2020_iclr/</guid>
      <description>&lt;p&gt;A fair and robust evaluation of Deep Graph Networks for graph classification tasks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://diningphil.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
   One 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   **Two** 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   Three 
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Notes on the Reparametrization Trick</title>
      <link>https://diningphil.github.io/project/reparamtrick/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/project/reparamtrick/</guid>
      <description>&lt;p&gt;One of the most popular articles of the last years in the Machine Learning community is the &lt;a href=&#34;https://arxiv.org/pdf/1312.6114.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Auto-Encoding Variational Bayes&lt;/a&gt;, which also includes the so-called reparametrization trick. Intrigued by what was sketched in the article, I decided to work out the details of this reparametrization, covering 2 of the 3 cases described (but I guess the third one can be derived from the first 2). I want to share my calculations with you. I have learned (and reviewed) a lot in the process, which was not directly related to the equations themselves. Sharing is the only way to make real progress as a community. Have a look &lt;a href=&#34;https://diningphil.github.io/media/reparamtrick_notes.pdf&#34; target=&#34;_blank&#34;&gt;Here&lt;/a&gt;, and please contact me in case the steps are not correct or contain imprecise notation.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update, 2018-12-10&lt;/em&gt;: I have added the solution of the integrals of Appendix B. This was really useful to get familiar with the gaussian integral and Fubini&amp;rsquo;s theorem.&lt;/p&gt;
&lt;p&gt;Special thanks to Iacopo Ripoli for his decisive and helpful insights!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Derivations of SNE and t-SNE</title>
      <link>https://diningphil.github.io/project/tsnederivation/</link>
      <pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/project/tsnederivation/</guid>
      <description>&lt;p&gt;Recently I was looking at Stochastic Neigbhor Embedding &lt;a href=&#34;https://papers.nips.cc/paper/2276-stochastic-neighbor-embedding.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(SNE)&lt;/a&gt; and its t-distributed version &lt;a href=&#34;http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(t-SNE)&lt;/a&gt;, but I could not find the exact steps to derive the gradient of the loss function (there are small errors in the t-SNE article and no info in the SNE one), so I decided to carry on the derivation and share it. I hope this can be of any help to those who are studying the same topic. &lt;a href=&#34;https://diningphil.github.io/media/sne_tsne.pdf&#34; target=&#34;_blank&#34;&gt;Here&lt;/a&gt; you find the pdf: please let me know if you spot an error! (Picture taken from t-SNE paper)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Contextual Graph Markov Model: a Deep and Generative Approach to Graph Processing</title>
      <link>https://diningphil.github.io/publication/2018_icml/</link>
      <pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/publication/2018_icml/</guid>
      <description>&lt;p&gt;A deep, probabilistic, and scalable machine learning model for graphs. Work done as part of my master thesis.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PyDGN</title>
      <link>https://diningphil.github.io/project/pydgn/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/project/pydgn/</guid>
      <description>&lt;h2 id=&#34;wikihttpsgithubcomdiningphilpydgnwiki&#34;&gt;&lt;a href=&#34;https://github.com/diningphil/PyDGN/wiki&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wiki&lt;/a&gt;&lt;/h2&gt;
&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;This is a Python library to easily experiment with &lt;a href=&#34;https://arxiv.org/abs/1912.12693&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep Graph Networks&lt;/a&gt; (DGNs). It provides automatic management of data splitting, loading and the most common experimental settings. It also handles both model selection and risk assessment procedures, by trying many different configurations in parallel (CPU).
This repository is built upon the &lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pytorch Geometric Library&lt;/a&gt;, which provides support for data management.&lt;/p&gt;
&lt;p&gt;If you happen to use or modify this code, please remember to cite our tutorial paper:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1912.12693&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bacciu Davide, Errica Federico, Micheli Alessio, Podda Marco: &lt;em&gt;A Gentle Introduction to Deep Learning for Graphs&lt;/em&gt;&lt;/a&gt;, Neural Networks, 2020. DOI: &lt;code&gt;10.1016/j.neunet.2020.06.006&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you are interested in a rigorous evaluation of Deep Graph Networks, check this out:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://openreview.net/pdf?id=HygDF6NFPB&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Errica Federico, Podda Marco, Bacciu Davide, Micheli Alessio: &lt;em&gt;A Fair Comparison of Graph Neural Networks for Graph Classification&lt;/em&gt;&lt;/a&gt;. &lt;em&gt;Proceedings of the 8th International Conference on Learning Representations (ICLR 2020).&lt;/em&gt; &lt;a href=&#34;https://github.com/diningphil/gnn-comparison&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Code&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;New features&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Support to multiprocessing in GPU is now provided via Ray (see v0.4.0)!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation:&lt;/h2&gt;
&lt;p&gt;(We assume &lt;strong&gt;git&lt;/strong&gt; and &lt;strong&gt;Miniconda/Anaconda&lt;/strong&gt; are installed)&lt;/p&gt;
&lt;p&gt;First, make sure gcc 5.2.0 is installed: &lt;code&gt;conda install -c anaconda libgcc=5.2.0&lt;/code&gt;. Then, &lt;code&gt;echo $LD_LIBRARY_PATH&lt;/code&gt; should always contain &lt;code&gt;:/home/[your user name]/miniconda3/lib&lt;/code&gt;. Then run from your terminal the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;source install.sh [&amp;lt;your_cuda_version&amp;gt;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Where &lt;code&gt;&amp;lt;your_cuda_version&amp;gt;&lt;/code&gt; is an optional argument that can be either &lt;code&gt;cpu&lt;/code&gt;, &lt;code&gt;cu92&lt;/code&gt;, &lt;code&gt;cu101&lt;/code&gt;, &lt;code&gt;cu102&lt;/code&gt; or &lt;code&gt;cu110&lt;/code&gt; for Pytorch 1.7.0. If you do not provide a cuda version, the script will default to &lt;code&gt;cpu&lt;/code&gt;. The script will create a virtual environment named &lt;code&gt;pydgn&lt;/code&gt;, with all the required packages needed to run our code. &lt;strong&gt;Important:&lt;/strong&gt; do NOT run this command using &lt;code&gt;bash&lt;/code&gt; instead of &lt;code&gt;source&lt;/code&gt;!&lt;/p&gt;
&lt;p&gt;Remember that &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyTorch MacOS Binaries dont support CUDA, install from source if CUDA is needed&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;usage&#34;&gt;Usage:&lt;/h2&gt;
&lt;h3 id=&#34;preprocess-your-dataset-see-also-wiki&#34;&gt;Preprocess your dataset (see also Wiki)&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;python build_dataset.py --config-file [your data config file]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;launch-an-experiment-in-debug-mode-see-also-wiki&#34;&gt;Launch an experiment in debug mode (see also Wiki)&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;python launch_experiment.py --config-file [your exp. config file] --splits-folder [the splits MAIN folder] --data-splits [the splits file] --data-root [root folder of your data] --dataset-name [name of the dataset] --dataset-class [class that handles the dataset] --max-cpus [max cpu parallelism] --max-gpus [max gpu parallelism] --gpus-per-task [how many gpus to allocate for each job] --final-training-runs [how many final runs when evaluating on test. Results are averaged] --result-folder [folder where to store results]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To debug your code it is useful to add &lt;code&gt;--debug&lt;/code&gt; to the command above. Notice, however, that the CLI will not work as expected here, as code will be executed sequentially. After debugging, if you need sequential execution, you can use &lt;code&gt;--max-cpus 1 --max-gpus 1 --gpus-per-task [0/1]&lt;/code&gt; without the &lt;code&gt;--debug&lt;/code&gt; option.&lt;/p&gt;
&lt;h2 id=&#34;credits&#34;&gt;Credits:&lt;/h2&gt;
&lt;p&gt;This is a joint project with &lt;strong&gt;Marco Podda&lt;/strong&gt; (&lt;a href=&#34;https://github.com/marcopodda&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Github&lt;/a&gt;/&lt;a href=&#34;https://sites.google.com/view/marcopodda/home&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Homepage&lt;/a&gt;), whom I thank for his relentless dedication.&lt;/p&gt;
&lt;p&gt;Many thanks to &lt;strong&gt;Antonio Carta&lt;/strong&gt; (&lt;a href=&#34;https://github.com/AntonioCarta&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Github&lt;/a&gt;/&lt;a href=&#34;http://pages.di.unipi.it/carta&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Homepage&lt;/a&gt;) for incorporating the Ray library (see v0.4.0) into PyDGN! This will be of tremendous help.&lt;/p&gt;
&lt;h2 id=&#34;contributing&#34;&gt;Contributing&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;This research software is provided as-is&lt;/strong&gt;. We are working on this library in our spare time.&lt;/p&gt;
&lt;p&gt;If you find a bug, please open an issue to report it, and we will do our best to solve it. For generic/technical questions, please email us rather than opening an issue.&lt;/p&gt;
&lt;h2 id=&#34;license&#34;&gt;License:&lt;/h2&gt;
&lt;p&gt;PyDGN is GPL 3.0 licensed, as written in the LICENSE file.&lt;/p&gt;
&lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting&lt;/h2&gt;
&lt;p&gt;If you get errors like &lt;code&gt;/lib64/libstdc++.so.6: version `GLIBCXX_3.4.21&#39; not found&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;make sure gcc 5.2.0 is installed: &lt;code&gt;conda install -c anaconda libgcc=5.2.0&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;echo $LD_LIBRARY_PATH&lt;/code&gt; should contain &lt;code&gt;:/home/[your user name]/[your anaconda or miniconda folder name]/lib&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;after checking the above points, you can reinstall everything with pip using the &lt;code&gt;--no-cache-dir&lt;/code&gt; option&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://diningphil.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diningphil.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
